{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course **cs231n** offered by Stanford can help you understand what CNN is and how it works:\n",
    "\n",
    "http://cs231n.stanford.edu/\n",
    "\n",
    "All the lectures of 2017 can be found on Youtube:\n",
    "\n",
    "https://www.youtube.com/playlist?list=PL3FW7Lu3i5JvHM8ljYj-zLfQRF3EO8sYv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keynotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1 - Introduction to Convolutional Neural Networks for Visual Recognition\n",
    "\n",
    "\n",
    "### The is history of visual recognition\n",
    "Image segmentation => face detection => object recognition\n",
    "\n",
    "2006-2012, benchmark data set for object recognition: PASCAL Virual Object Challenge\n",
    "\n",
    "Image Net: 22K categories and 14M images (www.image-net.org)\n",
    "\n",
    "The error rate of object recognition had a significant drop in 2012, and the winning algorithm was `Convolutional Neural Network`\n",
    "\n",
    "### Overview of cs231n\n",
    "\n",
    "Focus on the most important problem of visual recognition: image classification.\n",
    "\n",
    "Also some other problems that related to image classificatio:\n",
    " - object detaction\n",
    " - action classificatio\n",
    " - image captioning\n",
    " \n",
    "The quest of visual intelligence is far beyond object recognition.\n",
    " \n",
    "The algorithm was there since the 90s, the reasons for why it's getting popular are:\n",
    " - compute power\n",
    "  - number of transistors 10<sup>6</sup> => 10<sup>9</sup>\n",
    "  - GPU\n",
    " - data\n",
    "    much more data available\n",
    "    \n",
    "### Pre-requisite of this course\n",
    " - proficiency in python\n",
    " - College Calculas and Linear Algebra\n",
    " - Equilavent knowledge of cs229 (machine learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2 - Image Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3 - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4 -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 5 - Convolutional Neural Networks\n",
    "\n",
    "A typical convolutional neural network in built with three diffenent types of layers.\n",
    "\n",
    "### Convolution Layer (Conv Layer)\n",
    "\n",
    "- Accepts a volume of size W<sub>1</sub> × H<sub>1</sub> × D<sub>1</sub>\n",
    "- Requires four hyperparameters\n",
    "  - Number of filters K\n",
    "  - their spatial extent F\n",
    "  - the stride S\n",
    "  - the amount of zero padding P\n",
    "- Produces a volume of size W<sub>2</sub> × H<sub>2</sub> × D<sub>2</sub>, where\n",
    "  - W<sub>2</sub> = (W<sub>1</sub> - F + 2P)/S + 1\n",
    "  - H<sub>2</sub> = (H<sub>1</sub> - F + 2P)/S + 1 (i.e. width are hight are computed equally by symmetry)\n",
    "  - D<sub>2</sub> = K\n",
    "- With parameter sharning, it introduces F × F × D<sub>1</sub> weights per filter, for a total of  (F × F × D<sub>1</sub>) × K weights and K biases\n",
    "- In the output volume, the d-th depth slice (of size W<sub>2</sub> × H<sub>2</sub>) is the result of performing a valid convolution of the d-th filter over the input volume with a stride of S, and then offset by d-th bias.\n",
    "\n",
    "### Pooling Layer\n",
    "\n",
    "- Makes the representations smaller and more manageable\n",
    "- Operates over each activation map independently\n",
    "- Accepts a volume of size W<sub>1</sub> × H<sub>1</sub> × D<sub>1</sub>\n",
    "- Requires two hyperparameters\n",
    "  - their spatial extent F\n",
    "  - the stride S\n",
    "- Produces a volume of size W<sub>2</sub> × H<sub>2</sub> × D<sub>2</sub>, where\n",
    "  - W<sub>2</sub> = (W<sub>1</sub> - F)/S + 1\n",
    "  - H<sub>2</sub> = (H<sub>1</sub> - F)/S + 1\n",
    "  - D<sub>2</sub> = D<sub>1</sub>\n",
    "- Introduces zero parematers since it computes a fixed function of the input\n",
    "- Note that it is not common to use zero-padding for polling layers\n",
    "\n",
    "### Fully Connected Layer (FC Layer)\n",
    "\n",
    "- Contains neurons that connect to the entire input volume, as in ordinary Neural Networks\n",
    "\n",
    "### Summary\n",
    "\n",
    "- ConvNets stack CONV, POOL, FC Layers\n",
    "- Trend towards smaller filter and deeper architectures\n",
    "- Trend towards getting rid of POOL/FC layers (just CONV)\n",
    "- Typical architectures look like\n",
    "\\begin{align}[(CONV-RELU)*N-POOL?]*M-(FC-RELU)*K,SOFTMAX\\end{align}\n",
    "  where N is natually up to ~5, M is large, 0 <= K <= 2\n",
    "  - but recent advances such as ResNet/GoogleNet challenge this paradigm\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
