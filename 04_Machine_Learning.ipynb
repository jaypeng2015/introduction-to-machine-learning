{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course cs229 offered by Stanford can help you understand Machine Learning better:\n",
    "\n",
    "\n",
    "https://www.youtube.com/playlist?list=PL7FnO5AWye3YU4LeayDKP1AhOqJBAdBYt\n",
    "\n",
    "The latest course website is at: http://cs229.stanford.edu/\n",
    "\n",
    "It's been 10 years late to this course so you will probably find that some of the terms have change a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keynotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1\n",
    "\n",
    "### The definition of Machine Learning:\n",
    "\n",
    "Arthul Samuel (1959): Fields of study that gives computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "\n",
    "Tom M. Mitchell (1998): A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "### Main focus of this course\n",
    " - Supervised Learning\n",
    "   - regression problems\n",
    "   - classification problems\n",
    " - Learning Theory\n",
    " - Unsupervised Learning\n",
    "   - clustering problem\n",
    "   - social network analysis\n",
    "   - market segmentation\n",
    "   - astronomical data analysis\n",
    " - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2\n",
    " - Linear Regression\n",
    " - Gradient Descent\n",
    " - Normal Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "This is commanly used in `Supervised Learning`.\n",
    "\n",
    "Take house price prediction for example. \n",
    "\n",
    "Let's say if we have different variables as features of the house, such as\n",
    " - x<sub>1</sub>: land size\n",
    " - x<sub>2</sub>: number of bedrooms\n",
    " \n",
    "Then a prediction function, which is also called `hypothesis`, can be discribed as:\n",
    "    \n",
    "\\begin{equation*}\n",
    "h\\left( x\\right) = h_{\\Theta}(x) = \\sum_{i=0}^n \\Theta_i x_i = \\Theta^Tx\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- define x<sub>0</sub>=1\n",
    "- n is the number of variables which is 2 here\n",
    "- w is the weight of the variables\n",
    "- Œò's are called parameters\n",
    "\n",
    "To train this `hypothesis`, we define \n",
    "\n",
    "\\begin{equation*}\n",
    "J(\\Theta)=\\frac12\\sum_{j=1}^m(h_\\Theta(x^{(j)})-y^{(j)})^2\n",
    "\\end{equation*}\n",
    "\n",
    "- y: the actual price of the house\n",
    "- m: the number of traning data\n",
    "\n",
    "J(Œò) is called the `cost`, then the next step will be using some algorithm to minimise the cost.\n",
    " \n",
    "- start with some Œò, for example Œò=0\n",
    "- keep changing Œò to reduce "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "#### Batch Gradient Descent\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Theta_i:=\\Theta_i-\\alpha{\\frac{\\partial}{\\partial\\Theta_i}}J(\\Theta)\n",
    "\\end{equation*}\n",
    "\n",
    "- ùõº: is called the learning rate which controls how large the step takes\n",
    "\n",
    "If we have only one train example, then\n",
    "\n",
    "\\begin{equation*}\n",
    "{\\frac{\\partial}{\\partial\\Theta_i}}J(\\Theta) = {\\frac{\\partial}{\\partial\\Theta_i}}\\frac12(h_\\Theta(x)-y)^2\n",
    "= {\\frac{\\partial}{\\partial\\Theta}}\\frac12(h_\\Theta(x)-y)^2\n",
    "= 2 \\times \\frac12 \\left( h_\\Theta\\left( x \\right)-y \\right) \\times \\frac{\\partial}{\\partial\\Theta}\n",
    "\\left( h_\\Theta\\left( x \\right)-y \\right)\n",
    "= \\left( h_\\Theta\\left( x \\right)-y \\right)x\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Generally for m data examples, the whole algorithm is described as:\n",
    "\n",
    "Repeat until convergence:\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\Theta_i := \\Theta_i - \\alpha\\sum_{j=1}^m(h_\\Theta(x^{(j)})-y^{(j)})x_{i}^{(j)}\n",
    "\\end{equation*}\n",
    "\n",
    "This algorithm is called `Batch Gradient Descent`, and for each step it needs to consume the whole trainning set.\n",
    "\n",
    "When you have a large trainning set, for example, 1 million, then you may need to consider another algorithm which is called `Stochastic Gradient Descent`, or `Incremental Gradient Descent`\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "Repeat until convergence:\n",
    "\n",
    "    for j from 1 to m:\n",
    "\\begin{equation*}\n",
    "\\Theta_i := \\Theta_i - \\alpha(h_\\Theta(x_{i}^{(j)})-y_{i}^{(j)})x_{i}^{(j)}\n",
    "\\end{equation*}\n",
    "\n",
    "This runs much faster on large trainning sets, and the results tend to the region near the globla minimum, not exactly the globla minimum but that's good enough.\n",
    "\n",
    "### Normal Equations\n",
    "\n",
    "A close form but simplified solution to Batch Gradient Descent when the expeted output is in R<sup>1</sup>.\n",
    "\n",
    "Define:\n",
    "\\begin{equation*}\n",
    "\\nabla J(\\Theta) = \\begin{vmatrix}\\frac{\\partial}{\\partial\\Theta_0}\\\\\\frac{\\partial}{\\partial\\Theta_1}\\\\...\\\\\\frac{\\partial}{\\partial\\Theta_n}\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{equation*}\n",
    "\\Theta := \\Theta - \\alpha\\nabla J(\\Theta)\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "More generally:\n",
    "\n",
    "If you have a function f to map the space of m by n matrix A to a vector, \n",
    "\n",
    "Define:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_A f(A) = \\begin{vmatrix}\n",
    "\\frac{\\partial f}{\\partial A_{11}}&\\frac{\\partial f}{\\partial A_{12}}&...&\\frac{\\partial f}{\\partial A_{1n}}\\\\\n",
    "\\frac{\\partial f}{\\partial A_{21}}&\\frac{\\partial f}{\\partial A_{22}}&...&\\frac{\\partial f}{\\partial A_{2n}}\\\\...&...&...&...\\\\\n",
    "\\frac{\\partial f}{\\partial A_{m1}}&\\frac{\\partial f}{\\partial A_{m2}}&...&\\frac{\\partial f}{\\partial A_{mn}}\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Also if m = n, define `trace`:\n",
    "\n",
    "\\begin{equation*}Tr(A) = \\sum_{i=1}^nA_{ii}\\end{equation*}\n",
    "\n",
    "Then the facts:\n",
    "\\begin{equation*}Tr(a) = a \\space \\space // \\space n=1\\end{equation*}\n",
    "\\begin{equation*}Tr(A) = Tr(A^T)\\end{equation*}\n",
    "\\begin{equation*}Tr(AB) = Tr(BA)\\end{equation*}\n",
    "\\begin{equation*}Tr(ABC) = Tr(CAB) = Tr(BCA)\\end{equation*}\n",
    "\n",
    "Also Suppose f(A) = Tr(AB), then:\n",
    "\n",
    "\\begin{equation*}\\nabla_A f(A) = \\nabla_A Tr(AB) = B^T\\end{equation*}\n",
    "\n",
    "And finally a tricky one:\n",
    "\\begin{equation*}\\nabla_A Tr(ABA^TC) = CBA + C^TAB^T\\end{equation*}\n",
    "\n",
    "By having all these facts above, define matrix X to be all the inputs from traninig set (the `design matrix`):\n",
    "\n",
    "\\begin{equation*}X = \\begin{vmatrix}x^{(1)T}\\\\x^{(2)T}\\\\..\\\\x^{(m)T}\\end{vmatrix}\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\n",
    "\\begin{equation*}X\\Theta = \\begin{vmatrix}x^{(1)T}\\\\x^{(2)T}\\\\..\\\\^{(m)T}\\end{vmatrix}\\Theta\n",
    "= \\begin{vmatrix}x^{(1)T}\\Theta\\\\x^{(2)T}\\Theta\\\\...\\\\x^{(m)T}\\Theta\\end{vmatrix}\n",
    "= \\begin{vmatrix}h_\\Theta(x^{(1)})\\\\h_\\Theta(x^{(2)})\\\\...\\\\h_\\Theta(x^{(m)})\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Define vector y as all the target values:\n",
    "\n",
    "\\begin{equation*}y = \\begin{vmatrix}y^{(1)}\\\\y^{(2)}\\\\..\\\\y^{(m)}\\end{vmatrix}\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*}X\\Theta - y = \\begin{vmatrix}h_\\Theta(x^{(1)})-y^{(1)}\\\\h_\\Theta(x^{(2)})-y^{(2)}\\\\...\\\\h_\\Theta(x^{(m)})-y^{(m)}\\end{vmatrix}\\end{equation*}\n",
    "\n",
    "Recall:\n",
    "\n",
    "\\begin{equation*} z^Tz = \\sum_iz_i^2\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*}\\frac12(X\\Theta - y)^T(X\\Theta - y) = \\frac12\\sum_{j=1}^m (h_\\Theta(x^{(j)})-y^{(j)})^2 = J(\\Theta)\\end{equation*}\n",
    "\n",
    "Try to solve **‚àá<sub>ùúÉ</sub>ùêΩ(ùúÉ) = 0** by using the facts above:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{gather*}\\nabla_\\Theta J(\\Theta) \n",
    "= \\nabla_\\Theta \\frac12(X\\Theta - y)^T(X\\Theta - y) \\\\\n",
    "= \\frac12 \\nabla_\\Theta (X\\Theta - y)^T(X\\Theta - y) \\\\\n",
    "= \\frac12 \\nabla_\\Theta (\\Theta^TX^TX\\Theta - \\Theta^TX^Ty - y^TX\\Theta + y^Ty) \\\\\n",
    "= \\frac12 \\nabla_\\Theta Tr(\\Theta^TX^TX\\Theta - \\Theta^TX^Ty - y^TX\\Theta + y^Ty)  \\\\\n",
    "= \\frac12 ((\\nabla_\\Theta Tr(\\Theta\\Theta^TX^TX) - \\nabla_\\Theta Tr(y^TX\\Theta) - \\nabla_\\Theta Tr(y^TX\\Theta) + 0)  \\\\\n",
    "= \\frac12 (X^TX\\Theta + X^TX\\Theta  - X^Ty - X^Ty) \\\\\n",
    "= X^TX\\Theta - X^Ty) = 0 \n",
    "\\end{gather*}\n",
    "\n",
    "So \n",
    "\n",
    "\\begin{equation*} X^TX\\Theta = X^Ty\\end{equation*}\n",
    "\n",
    "The equation is called the `normal equations` and we can slove:\n",
    "\n",
    "\\begin{equation*} \\Theta = (X^TX)^{-1}X^Ty\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3\n",
    "\n",
    "- Linear Regression \n",
    " - Locally Weighted Regression\n",
    "- Portabilistic Interperception\n",
    "- Logistic Regression\n",
    "  - Digression Perception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem\n",
    "\n",
    "If the features are poorly chosen, the model can be\n",
    " - underfitting\n",
    " - overfitting\n",
    " \n",
    "For now we use a class of algorithms called `non-parametric learning algorithm` that help to alleviate this problem.\n",
    "\n",
    "- parametric:  fixed Œòs\n",
    "- non-parametric: no. of parameters grows with m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally Weighted Regression\n",
    "\n",
    " - also called `loess` or `lowess`\n",
    " - non-parametric learning algorithm\n",
    " \n",
    "LWR: fit Œò to minimise \n",
    " \n",
    "\\begin{align} \\sum_iw^{(i)}(y^{(i)}-\\Theta^TX^{(i)})^2 \\end{align}\n",
    " \n",
    "Where\n",
    " \n",
    "\\begin{equation*} w^{(i)} = \\exp(-\\frac{(x^{(i)} - x)^2}{2 \\tau}) \\end{equation*}\n",
    "  \n",
    " - If |x<sup>(i)</sup> - x| is small, then w<sup>(i)</sup> is close to 1.\n",
    " - If |x<sup>(i)</sup> - x| is large, then w<sup>(i)</sup> is close to 0.\n",
    " - ùúè (bandwith) controls how rapidly the weight drops\n",
    " \n",
    "When doing predictions, it needs to fit ùúÉ to the entire tranning set again.\n",
    "\n",
    "And it doesn't solve the problem if ùúè is badly chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portabilistic Interperception\n",
    "\n",
    "Assume\n",
    "\n",
    "\\begin{equation*} y^{(i)} = \\Theta^Tx^{(i)} + \\epsilon^{(i)} \\end{equation*}\n",
    "\n",
    "\\begin{equation*} \\epsilon^{(i)} = error \\end{equation*}\n",
    "\n",
    "Assume ùúñ<sup>(i)</sup> have a portability distribution - called `Normal Distribution` or `Gaussion Distribution`:\n",
    "\\begin{align} N(0, \\sigma^2) \\end{align}\n",
    "\n",
    "**Why?**\n",
    " - it's mathematically convinient\n",
    " = for most of the problems it works...\n",
    "\n",
    "So the portability distribution of ùúñ<sup>(i)</sup>:\n",
    "\n",
    "\\begin{equation*} P(\\epsilon^{(i)}) = \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{{\\epsilon^{(i)}}^2}{2\\sigma^2}) \\end{equation*}\n",
    "\n",
    "This implies that the portability distribution of y<sup>(i)</sup> by given x<sup>(i)</sup> and ùúÉ:\n",
    "\n",
    "\\begin{equation*} P(y^{(i)}|x^{(i)}, \\Theta) = \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\Theta^Tx^{(i)}})^2}{2\\sigma^2}) \\end{equation*}\n",
    "\n",
    "Also writen as: \\begin{align} N(\\Theta^Tx^{(i)}, \\sigma^2) \\end{align}\n",
    "\n",
    "One more assumption is that ùúñ<sup>(i)</sup> is IID, which mean they are independently identically distributed.\n",
    "\n",
    "Then define the likelihood of Œò:\n",
    "\n",
    "\\begin{equation*} L(\\Theta) = \\prod_1^m P(y|X, \\Theta) = \\prod_1^m \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\Theta^Tx^{(i)}})^2}{2\\sigma^2}) \\end{equation*}\n",
    "\n",
    "`Likelihood` here is actually portability.\n",
    "\n",
    "Then we need to maximise the `Likelihood`: choose ùúÉ to maximise the ùêø(ùúÉ).\n",
    "\n",
    "Define \\begin{gather*} l(\\Theta) = \\log L(\\Theta) = \\log \\prod_1^m \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\Theta^Tx^{(i)}})^2}{2\\sigma^2}) \\\\ \n",
    "= \\sum_1^m \\log  \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\Theta^Tx^{(i)}})^2}{2\\sigma^2}) \\\\\n",
    "= m \\log \\frac1{\\sqrt{2\\pi}\\sigma} + \\sum_1^m(-\\frac{({y^{(i)}-\\Theta^Tx^{(i)}})^2}{2\\sigma^2})\n",
    "\\end{gather*}\n",
    "\n",
    "So maximising ùëô(ùúÉ) is the same as minimising \n",
    "\\begin{equation*} \\frac12 \\sum_1^m ({y^{(i)}-\\Theta^Tx^{(i)}})^2 = J(\\Theta) \\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Generally it's a bad idea to apply linear regression to classification problems.\n",
    "\n",
    "When we need to classify \\begin{align}y \\space \\epsilon \\space \\{0, 1\\}  \\end{align} with a prediction function: \n",
    "\n",
    "\\begin{align}h_\\Theta (x) \\space \\epsilon \\space [0, 1]  \\end{align}\n",
    "\n",
    "Then choose:\n",
    "\n",
    "\\begin{align}h_\\Theta (x) = g(\\Theta^Tx) = \\frac1{1+e^{-\\Theta^Tx}}\\end{align}\n",
    "\n",
    "\n",
    "The function `g` here:\n",
    "\n",
    "\\begin{align} g(z) = \\frac1{1+e^{-z}}\\end{align}\n",
    "\n",
    "is called `sigmond function` or `logistic function`.\n",
    "\n",
    "There are reasons of chosing this function.\n",
    "\n",
    "Then it comes to the portability of y=1 or y=0:\n",
    "\n",
    "\\begin{equation*} P(y=1|x;\\Theta) = h_\\Theta(x) \\end{equation*}\n",
    "\\begin{equation*} P(y=0|x;\\Theta) = 1 - h_\\Theta(x) \\end{equation*}\n",
    "\n",
    "Write them in one line:\n",
    "\n",
    "\\begin{equation*} P(y|x;\\Theta) = h_\\Theta(x)^y(1-h_\\Theta(x)^{1-y}) \\end{equation*}\n",
    "\n",
    "Then the likely hood of Œò:\n",
    "\n",
    "\\begin{equation*} L(\\Theta) = \\prod_{i}ùëÉ(ùë¶^{(i)}|ùëã^{(i)},ùúÉ) = \\prod_i h_\\Theta(x^{(i)})^{y^{(i)}}(1-h_\\Theta(x^{(i)})^{1-y^{(i)}})\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*} l(\\Theta) = \\log L(\\Theta) = \\log \\prod_i h_\\Theta(x^{(i)})^{y^{(i)}}(1-h_\\Theta(x^{(i)})^{1-y^{(i)}})\n",
    "= \\sum_1^my^{(i)}\\log h_\\Theta(x^{(i)}) + (1-y^{(i)})\\log(1-h_\\Theta(x^{(i)}))\n",
    "\\end{equation*}\n",
    "\n",
    "The algorithm to mixmise this l(ùúÉ) is similar to Gradient Descent => Gradient Ascent:\n",
    "\n",
    "\\begin{equation*}\\Theta := \\Theta + \\alpha \\nabla_\\Theta l(\\Theta) \\end{equation*}\n",
    "\n",
    "Since:\n",
    "\n",
    "\\begin{equation*}\\frac{\\partial}{\\partial \\Theta_j}l(\\Theta) = \\sum_{i=1}^m (y^{(i)}-h_\\Theta(x^{(i)}))x_j^{(i)} \\end{equation*}\n",
    "\n",
    "It turns out that Gradient Ascent:\n",
    "\n",
    "\\begin{equation*}\\Theta_j := \\Theta_j + \\alpha \\sum_{i=1}^m (y^{(i)}-h_\\Theta(x^{(i)}))x_j^{(i)} \\end{equation*}\n",
    "\n",
    "This looks the same as formular in Batch Gradient Descent expect that there is a + not -. However, this is a totally a different algorithm and the key difference is the function **h<sub>Œò</sub>(x<sup>(i)</sup>)**, which is not a linear function any more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression Perception\n",
    "\n",
    "Change the sigmond funtion to another function (step function):\n",
    "\n",
    "g(z) when z>=0 then 1 else 0.\n",
    "\n",
    "This become a simpler algorithm than logistic regression and later on we can use this as a building block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 4\n",
    "\n",
    "- Logistic Regression\n",
    "  - Newton's Method\n",
    "- Exponential Family\n",
    "- Generalised Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Newton's Method\n",
    "\n",
    "Given function f(Œò), find Œò that makes f(ùúÉ)=0.\n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "  Chose a inital Œò, called Œò<sup>(0)<sup>\n",
    "  \n",
    "  Define Œî is the difference between Œò<sup>(0)</sup> and Œò<sup>(1)</sup>.\n",
    "    \n",
    "  Then because\n",
    "  \n",
    "  \\begin{equation}f‚Äô(\\Theta^{(0)}) = \\frac{f(\\Theta^{(0)})}\\Delta\\end{equation}\n",
    "  \n",
    "  Which implies that:\n",
    "  \n",
    "  \\begin{equation}\\Delta = \\frac{f(\\Theta^{(0)})}{f‚Äô(\\Theta^{(0)})}\\end{equation}\n",
    "   \n",
    "  Therefore:\n",
    "  \n",
    "  \\begin{equation}\\Theta^{(1)} = \\Theta^{(0)} - \\frac{f(\\Theta^{(0)})}{f‚Äô(\\Theta^{(0)})}\\end{equation}\n",
    "  \n",
    "  More generally:\n",
    "  \n",
    "  \\begin{equation}\\Theta^{(tt_1)} = \\Theta^{(t)} - \\frac{f(\\Theta^{(t)})}{f‚Äô(\\Theta^{(t)})}\\end{equation}\n",
    "  \n",
    "  Then similar to waht we did before, define l(ùúÉ) = log f(ùúÉ) and find ùúÉ that makes l(ùúÉ) = 0.\n",
    "  \n",
    "  \\begin{equation}\\Theta^{(tt_1)} = \\Theta^{(t)} - \\frac{l‚Äô(\\Theta^{(t)})}{l‚Äô‚Äô(\\Theta^{(t)})}\\end{equation}\n",
    "    \n",
    "    \n",
    "  In general this is much faster than Gradient Descent.\n",
    "  \n",
    "  Each step of interation is:\n",
    "  \n",
    "    \n",
    "  \\begin{equation}\\Theta^{(tt_1)} = \\Theta^{(t)} - H^{-1}\\nabla_\\Theta l\\end{equation}\n",
    "  \n",
    "  where ‚àáŒòùëô is the usual gradient of your objective and H is the `Hession` matrix:\n",
    "  \n",
    "  \\begin{equation}H_{ij} = \\frac{\\partial^2l}{\\partial \\Theta_i \\partial \\Theta_j}\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exponential Family\n",
    "\n",
    "We've seen two different algorithms of P(y|x, Œò)\n",
    " - y ùúñ 1R, Gaussion => least squares linear regression\n",
    " - y ùúñ {0, 1}, Bernoulli => logistic regression \n",
    " \n",
    " They are actually special cases of a class of distributions called `Exponential Family`.\n",
    " \n",
    "Definition:\n",
    "\n",
    "\\begin{equation*}P(y |\\eta) = b(y) \\exp(\\eta^TT(y) - a(\\eta))\\end{equation*}\n",
    "\n",
    "where\n",
    "\n",
    "  - ùúÇ: natrual parameter\n",
    "  - T: safficient statistic (normally T(y)=y)\n",
    "  \n",
    "#### Bernoulli\n",
    "\n",
    "\\begin{gather*}\n",
    "P(y|\\phi) = \\phi^y(1-\\phi)^{1-y} \\\\\n",
    "= \\exp (\\log \\phi^y(1-\\phi)^{1-y}) \\\\\n",
    "= \\exp (y\\log y + (1-y)\\log (1-\\phi)) \\\\\n",
    "= \\exp(\\log\\frac{\\phi}{1-\\phi}y + \\log(1-\\phi))\n",
    "\\end{gather*}\n",
    "\n",
    "- ùúÇ : log(ùúô/(1‚àíùúô))\n",
    "- T(y): y\n",
    "- -a(ùúÇ): log(1‚àíùúô)\n",
    "- ùëè(ùë¶): 1\n",
    "\n",
    "Interestingly (Sigmond function pops up here):\n",
    "\n",
    "\\begin{gather*}\n",
    "\\phi = \\log\\frac{\\phi}{1-\\phi} => \\phi = \\frac1{1+e^{-\\eta}}\n",
    "\\end{gather*}\n",
    "\n",
    "\n",
    "\n",
    "\\begin{gather*}\n",
    "a(\\eta) = -\\log(1-\\phi) = log(1+e^\\eta)\n",
    "\\end{gather*}\n",
    "\n",
    "#### Gaussion\n",
    "\n",
    "\\begin{align}\n",
    " N(\\mu, \\sigma^2)\n",
    "\\end{align}\n",
    "\n",
    "Here to make things easier, set ùúé<sup>2</sup> = 0.\n",
    "\n",
    "\\begin{gather*}\n",
    "\\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{1}{2}(y-\\mu)^2)\n",
    "= \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{1}{2}y^2)\\exp (\\mu y-\\frac12\\mu^2)\n",
    "\\end{gather*}\n",
    "\n",
    "So similarly we can get ùúÇ, T(y), a(ùúÇ) and ùëè(ùë¶) from here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalised Linear Models\n",
    "\n",
    "Assume:\n",
    " - y|x;Œò  ~ ExpFamily(ùúÇ)\n",
    " - given x, the goal is to output E[T(y)|x], want h(x) = E[T(y)|x]\n",
    " - ùúÇ = Œò<sup>T</sup>x (design choice)\n",
    " \n",
    "#### Bernoulli Example\n",
    "\n",
    "  y|x;Œò  ~ ExpFamily(ùúÇ)\n",
    "  \n",
    "  For fixed x, Œò, algorithm output: \n",
    "  \n",
    "\\begin{gather*}\n",
    "h_\\Theta(x) = E[y|x;\\Theta] \\\\\n",
    "= P[y=1|x;\\Theta] \\\\\n",
    "= \\phi \\\\\n",
    "= \\frac1{1+e^{-\\eta}} \\\\\n",
    "= \\frac1{1+e^{-\\Theta^Tx}}\n",
    "\\end{gather*}\n",
    "\n",
    "The shows the process to find the learning algorithm when we know the data set belongs to some exponential family distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial\n",
    "\n",
    "y ùúñ {1, ..., k}\n",
    "\n",
    "Choose parameters: ùúô<sub>1</sub>, ùúô<sub>2</sub>, ... ùúô<sub>k-1</sub>\n",
    "\n",
    "We don't need ùúô<sub>k</sub> because ùúô<sub>k</sub> = 1 - (ùúô<sub>1</sub> + ùúô<sub>2</sub> + ... + ùúô<sub>k-1</sub>)\n",
    "\n",
    "The probability:\n",
    "\\begin{equation*}P(y=i) = \\phi_i\\end{equation*}\n",
    "\n",
    "And the T(y) in R<sup>k-1</sup>:\n",
    "\n",
    "\\begin{equation*}\n",
    "T(1)=\\begin{vmatrix}1\\\\0\\\\...\\\\0\\end{vmatrix}, T(2)=\\begin{vmatrix}0\\\\1\\\\...\\\\0\\end{vmatrix}, ..., T(k-1)=\\begin{vmatrix}0\\\\0\\\\...\\\\1\\end{vmatrix}, T(k)=\\begin{vmatrix}0\\\\0\\\\...\\\\0\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "If we define an indicator I{True}=1, I{False}=0, then\n",
    "\n",
    "\\begin{equation*}\n",
    "T(y)_i = I\\{y=i\\}\n",
    "\\end{equation*}\n",
    "\n",
    "Then the probability of y:\n",
    "\\begin{gather*}\n",
    "P(y) = \\phi_1^{I\\{y=1\\}}\\phi_2^{I\\{y=2\\}}...\\phi_k^{I\\{y=k\\}} \\\\\n",
    "= \\phi_1^{T(y_1)}\\phi_2^{T(y_2)}...\\phi_k^{1 - \\sum_j^{k-1}T(y_j)} \\\\\n",
    "= ... \\\\\n",
    "= b(y)\\exp (\\eta^TT(y)-a(\\eta))\n",
    "\\end{gather*}\n",
    "\n",
    "where:\n",
    "\n",
    "\\begin{gather*}\n",
    "\\eta = \\begin{vmatrix}\\log(\\phi_1/\\phi_k)\\\\...\\\\\\log(\\phi_{k-1}/\\phi_k)\\end{vmatrix} \\\\\n",
    "a(\\eta) = -\\log\\phi_k \\\\\n",
    "b(y)=1\n",
    "\\end{gather*}\n",
    "\n",
    "If write ùúô and a function of ùúÇ, and also choose ùúÇ<sub>i</sub>=Œò<sub>i</sub><sup>T</sup>x\n",
    "\n",
    "\\begin{gather*}\n",
    "\\phi_i = \\frac{e^\\eta_i}{1+\\sum_{j=1}^{k-1}e^\\eta_j} \\\\\n",
    "=\\frac{e^{\\Theta_i^Tx}}{1+\\sum_{j=1}^{k-1}e^{\\Theta_j^Tx}}\n",
    "\\end{gather*}\n",
    "\n",
    "Then the learning algorithm:\n",
    "\n",
    "\\begin{gather*}\n",
    "h_\\Theta(x) = E[T(y)|x;\\Theta] \\\\\n",
    "= E[\\begin{vmatrix}I\\{y=1\\}\\\\I\\{y=2\\}\\\\...\\\\I\\{y=k-1\\}\\end{vmatrix}|x;\\Theta] \\\\ \n",
    "= \\begin{vmatrix}\\phi_1\\\\\\phi_2\\\\...\\\\\\phi_{k-1}\\end{vmatrix} \\\\\n",
    "= \\begin{vmatrix}\\frac{e^{\\Theta_1^Tx}}{1+\\sum_{j=1}^{k-1}e^{\\Theta_j^Tx}}\\\\\\frac{e^{\\Theta_2^Tx}}{1+\\sum_{j=1}^{k-1}e^{\\Theta_j^Tx}}\\\\...\\\\\\frac{e^{\\Theta_{k-1}^Tx}}{1+\\sum_{j=1}^{k-1}e^{\\Theta_j^Tx}}\\end{vmatrix} \n",
    "\\end{gather*}\n",
    "\n",
    "And the algorisim is called **Softmax Regression**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 5\n",
    "\n",
    " - Generative learning algorithms\n",
    " - GDA\n",
    " - Disgression Gaussians\n",
    " - Generative vs Discriminative\n",
    " - Naive Bayes\n",
    " - Laplace Smoothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generative learning algorithms\n",
    "\n",
    "By modeling P(x|y) and P(y), by using Bays Rules:\n",
    "\n",
    "\\begin{equation*} P(y=1|x)=\\frac{P(x|y=1)P(x)}{P(x)}\\end{equation*}\n",
    "\n",
    "if necessary:\n",
    "\n",
    "\\begin{equation*} P(x)= P(y=0|x)P(x)+P(y=1|x)P(x) \\end{equation*}\n",
    "\n",
    "While the discriminative learning algorithms we learnt before:\n",
    " - learn P(y|x)\n",
    " -  or\n",
    " - learn H<sub>Œò</sub>(x) that outputs 0 or 1 directly\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDA\n",
    "\n",
    " A generative learning algorithm example, Gaussian Discriminative Analysis.\n",
    " \n",
    " - assume x in R<sup>n</sup>, continuous-valued\n",
    " - assume P(x|y) is Gaussian\n",
    " \n",
    "Model P(y) as a random Bernoulli variable and parameterised by ùúô:\n",
    "\n",
    "\\begin{equation*}P(y)=\\phi^y(1-\\phi^{(1-y)})\\end{equation*}\n",
    "\n",
    "\\begin{gather*}\n",
    "P(x|y=0) = \\frac{1}{(2\\pi)^{1/2}| \\Sigma |^{1/2}} \\exp (-\\frac12(x-\\mu_0)^T\\Sigma^{-1}(x-\\mu_0))\\\\\n",
    "P(x|y=1) = \\frac{1}{(2\\pi)^{1/2}| \\Sigma |^{1/2}} \\exp (-\\frac12(x-\\mu_1)^T\\Sigma^{-1}(x-\\mu_1))\n",
    "\\end{gather*}\n",
    "\n",
    "The parameters are ùúô,ùúá<sub>0</sub>,ùúá<sub>1</sub> and Œ£, so we can write down the log likelihood (joint likelihood):\n",
    "\n",
    "\\begin{gather*}\n",
    "l(\\phi,\\mu_0,\\mu_1,\\Sigma) = \\log\\prod_{i=1}^mP(x^{(i)},y^{(i)}) = \\log\\prod_{i=1}^mP(x^{(i)}|y^{(i)})P(y^{(i)})\n",
    "\\end{gather*}\n",
    "\n",
    "maximum likelihood:\n",
    "\n",
    "\n",
    "\\begin{gather*}\n",
    "\\phi = \\frac{\\Sigma_{i=1}^my^{(i)}}m=\\frac{\\Sigma_{i=1}^mI\\{y^{(i)}=1\\}}m \\\\\n",
    "\\mu_0 = \\frac{\\Sigma_{i=1}^mI\\{y^{(i)}=0\\}x^{(i)}}{\\Sigma_{i=1}^mI\\{y^{(i)}=0\\}} \\\\\n",
    "\\mu_1 = \\frac{\\Sigma_{i=1}^mI\\{y^{(i)}=1\\}x^{(i)}}{\\Sigma_{i=1}^mI\\{y^{(i)}=1\\}} \\\\\n",
    "\\Sigma = ... ( in \\space the \\space lecture \\space notes \\space somewhere...)\n",
    "\\end{gather*}\n",
    "\n",
    "Predict:\n",
    "\n",
    "\\begin{gather*}\n",
    "argmax_yP(y|x) = argmax_y\\frac{P(x|y)P(y)}{P(x)} = argmax_yP(x|y)P(y)\n",
    "\\end{gather*}\n",
    "\n",
    "If P(y) is uniform (P(y=0)=P(y=1)): then this is just argmax<sub>y</sub>P(x|y).\n",
    "\n",
    "PS: argmax <sub>y</sub>f(y) means the value of y that maximise f(y).\n",
    "\n",
    "Some interesting facts:\n",
    " - if x|y is Gaussian, then P(y=1|x) is logistic, but not vice versa.\n",
    "   - this means if the algorism will do better than logistic when x|y is Gaussian, it used more information from the data and also requires less trainning data\n",
    " - if x|y=1 is Poisson(ùúÜ<sub>1</sub>), x|y=0 is Poisson(ùúÜ<sub>0</sub>), then P(y=1|x) is logistic.\n",
    " - if x|y=1 is ExpFamily(ùúÇ<sub>1</sub>), x|y=0 is Poisson(ùúÇ<sub>0</sub>), then P(y=1|x) is also logistic.\n",
    "\n",
    "This shows the robustness of the logictic function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes\n",
    "\n",
    "Assume that we want to design span classifier to decide if an email is a span email or not.\n",
    "\n",
    "y belongs to {0, 1} (0: non span; 1: span)\n",
    "\n",
    "The first decision to make is how to reprecent the email using the feature vector x?\n",
    "\n",
    "One option is make a list a keywords, and if the email contains one of the words, set the relevant component of x to 1.\n",
    "\n",
    "\\begin{equation*}\n",
    "x= \\begin{vmatrix}1\\\\0\\\\1\\\\...\\\\0\\end{vmatrix}  (\\begin{vmatrix}a\\\\ad\\\\buy\\\\...\\\\zebra\\end{vmatrix})\n",
    "\\end{equation*}\n",
    "\n",
    "Now we want to model P(x|y) where x belongs to {0, 1}<sup>n</sup>, maybe n=50000, so there can be 2<sup>50000</sup> parameters which to many to use Multinomial.\n",
    "\n",
    "\\begin{gather*}\n",
    "P(x_1,x_2,...,x_{50000}|y) = P(x_1|y)P(x_2|y,x_1)...P(x_{50000}|y,x_1,x_2,...x_{49999})\n",
    "\\end{gather*}\n",
    "\n",
    "Also we assume that **x<sub>i</sub>'s are conditionally independent** by given y, normally this isn't true but we use it here so simply the equation:\n",
    "\n",
    "\\begin{gather*}\n",
    "P(x_1,x_2,...,x_{50000}|y) = P(x_1|y)P(x_2|y,x_1)...P(x_{50000}|y,x_1,x_2,...x_{49999}) \\\\\n",
    " = P(x_1|y)P(x_2|y)...P(x_{50000}|y) \\\\\n",
    " = \\prod_{i=1}^nP(x_i|y)\n",
    "\\end{gather*}\n",
    "\n",
    "Parameters:\n",
    "\\begin{gather*}\n",
    "\\phi_{i|y=1} = P(x_i=1|y=1) \\\\\n",
    "\\phi_{i|y=0} = P(x_i=1|y=0) \\\\\n",
    "\\phi_y = P(y=1)\n",
    "\\end{gather*}\n",
    "\n",
    "Therefore, the joint likelihood:\n",
    "\n",
    "\\begin{gather*}\n",
    "L(\\phi_y,\\phi_{i|y=1},\\phi_{i|y=0}) = \\prod_{i=1}^mP(x^{(i)},y^{(i)})\n",
    "\\end{gather*}\n",
    "\n",
    "Maximum likelihood:\n",
    "\n",
    "\\begin{gather*}\n",
    "\\phi_{j|y=1} = \\frac{\\sum_{i=1}^mI\\{x_j^{(i)}=1, y_j^{(i)}=1\\}}{\\sum_{i=1}^mI\\{y_j^{(i)}=1\\}} \\\\\n",
    "\\phi_y = \\frac{\\sum_{i=1}^mI\\{y_j^{(i)}=1\\}}{m} \\\\\n",
    "\\end{gather*}\n",
    "\n",
    "Then you can compute P(y|x) using Bayes Rule: \n",
    "\n",
    "\\begin{equation*}ùëÉ(ùë¶|ùë•)= \\frac{P(x|y)P(y)}{P(x)}\\end{equation*}\n",
    "\n",
    "\n",
    "But there is a problem:\n",
    "\n",
    "If a word appears the first time (never happened in the traning set but in the dictionary), for example, x<sub>30000</sub>, then\n",
    "\n",
    "\\begin{gather*}\n",
    "P(x_{30000}|y=1) = 0\\\\\n",
    "P(x_{30000}|y=0) = 0\n",
    "\\end{gather*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*}ùëÉ(ùë¶=1|ùë•)= \\frac{P(x|y=1)P(y=1)}{P(x|y=1)P(y=1)+P(x|y=0)P(y=0)} = \\frac00\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laplace Smoothing\n",
    "\n",
    "To fix the problem above, we need to slightly change P(y=1) from\n",
    "\n",
    "\\begin{equation*}P(y=1)=\\frac{\\#1's}{\\#0's+\\#1's}\\end{equation*}\n",
    "\n",
    "to\n",
    "\n",
    "\\begin{equation*}P(y=1)=\\frac{\\#1's + 1}{\\#0's + 1 +\\#1's + 1}\\end{equation*}\n",
    "\n",
    "More generally:\n",
    "\n",
    "if y belongs to {1,2,...,k}, change \n",
    "\n",
    "\\begin{equation*}P(y=j)=\\frac{\\sum_{j=1}^m I\\{y=j\\}}{m}\\end{equation*}\n",
    "\n",
    "to \n",
    "\n",
    "\\begin{equation*}P(y=j)=\\frac{\\sum_{j=1}^m I\\{y=j\\}+1}{m+k}\\end{equation*}\n",
    "\n",
    "So for Naive Bayes,\n",
    "\n",
    "\n",
    "\\begin{gather*}\n",
    "\\phi_{j|y=1} = \\frac{\\sum_{i=1}^mI\\{x_j^{(i)}=1, y_j^{(i)}=1\\} + 1}{\\sum_{i=1}^mI\\{y_j^{(i)}=1\\} + 2}\n",
    "\\end{gather*}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
