{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This course cs229 offered by Stanford can help you understand Machine Learning better:\n",
    "\n",
    "\n",
    "https://www.youtube.com/playlist?list=PL7FnO5AWye3YU4LeayDKP1AhOqJBAdBYt\n",
    "\n",
    "The latest course website is at: http://cs229.stanford.edu/\n",
    "\n",
    "It's been 10 years late to this course so you will probably find that some of the terms have change a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keynotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 1\n",
    "\n",
    "### The definition of Machine Learning:\n",
    "\n",
    "Arthul Samuel (1959): Fields of study that gives computers the ability to learn without being explicitly programmed.\n",
    "\n",
    "\n",
    "Tom M. Mitchell (1998): A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P if its performance at tasks in T, as measured by P, improves with experience E.\n",
    "\n",
    "### Main focus of this course\n",
    " - Supervised Learning\n",
    "   - regression problems\n",
    "   - classification problems\n",
    " - Learning Theory\n",
    " - Unsupervised Learning\n",
    "   - clustering problem\n",
    "   - social network analysis\n",
    "   - market segmentation\n",
    "   - astronomical data analysis\n",
    " - Reinforcement Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 2\n",
    " - Linear Regression\n",
    " - Gradient Descent\n",
    " - Normal Equations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "This is commanly used in `Supervised Learning`.\n",
    "\n",
    "Take house price prediction for example. \n",
    "\n",
    "Let's say if we have different variables as features of the house, such as\n",
    " - x<sub>1</sub>: land size\n",
    " - x<sub>2</sub>: number of bedrooms\n",
    " \n",
    "Then a prediction function, which is also called `hypothesis`, can be discribed as:\n",
    "    \n",
    "\\begin{equation*}\n",
    "h\\left( x\\right) = h_{\\theta}(x) = \\sum_{i=0}^n \\theta_i x_i = \\theta^Tx\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "- define x<sub>0</sub>=1\n",
    "- n is the number of variables which is 2 here\n",
    "- w is the weight of the variables\n",
    "- ùúÉ's are called parameters\n",
    "\n",
    "To train this `hypothesis`, we define \n",
    "\n",
    "\\begin{equation*}\n",
    "J(\\theta)=\\frac12\\sum_{j=1}^m(h_\\theta(x^{(j)})-y^{(j)})^2\n",
    "\\end{equation*}\n",
    "\n",
    "- y: the actual price of the house\n",
    "- m: the number of traning data\n",
    "\n",
    "J(ùúÉ) is called the `cost`, then the next step will be using some algorism to minimise the cost.\n",
    " \n",
    "- start with some ùúÉ, for example ùúÉ=0\n",
    "- keep changing ùúÉ to reduce "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent\n",
    "\n",
    "#### Batch Gradient Descent\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta_i:=\\theta_i-\\alpha{\\frac{\\partial}{\\partial\\theta_i}}J(\\theta)\n",
    "\\end{equation*}\n",
    "\n",
    "- ùõº: is called the learning rate which controls how large the step takes\n",
    "\n",
    "If we have only one train example, then\n",
    "\n",
    "\\begin{equation*}\n",
    "{\\frac{\\partial}{\\partial\\theta_i}}J(\\theta) = {\\frac{\\partial}{\\partial\\theta_i}}\\frac12(h_\\theta(x)-y)^2\n",
    "= {\\frac{\\partial}{\\partial\\theta}}\\frac12(h_\\theta(x)-y)^2\n",
    "= 2 \\times \\frac12 \\left( h_\\theta\\left( x \\right)-y \\right) \\times \\frac{\\partial}{\\partial\\theta}\n",
    "\\left( h_\\theta\\left( x \\right)-y \\right)\n",
    "= \\left( h_\\theta\\left( x \\right)-y \\right)x\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Generally for m data examples, the whole algorism is described as:\n",
    "\n",
    "Repeat until convergence:\n",
    "    \n",
    "\\begin{equation*}\n",
    "\\theta_i := \\theta_i - \\alpha\\sum_{j=1}^m(h_\\theta(x^{(j)})-y^{(j)})x_{i}^{(j)}\n",
    "\\end{equation*}\n",
    "\n",
    "This algorism is called `Batch Gradient Descent`, and for each step it needs to consume the whole trainning set.\n",
    "\n",
    "When you have a large trainning set, for example, 1 million, then you may need to consider another algorism which is called `Stochastic Gradient Descent`, or `Incremental Gradient Descent`\n",
    "\n",
    "#### Stochastic Gradient Descent\n",
    "\n",
    "Repeat until convergence:\n",
    "\n",
    "    for j from 1 to m:\n",
    "\\begin{equation*}\n",
    "\\theta_i := \\theta_i - \\alpha(h_\\theta(x_{i}^{(j)})-y_{i}^{(j)})x_{i}^{(j)}\n",
    "\\end{equation*}\n",
    "\n",
    "This runs much faster on large trainning sets, and the results tend to the region near the globla minimum, not exactly the globla minimum but that's good enough.\n",
    "\n",
    "### Normal Equations\n",
    "\n",
    "A close form but simplified solution to Batch Gradient Descent when the expeted output is in R<sup>1</sup>.\n",
    "\n",
    "Define:\n",
    "\\begin{equation*}\n",
    "\\nabla J(\\theta) = \\begin{vmatrix}\\frac{\\partial}{\\partial\\theta_0}\\\\\\frac{\\partial}{\\partial\\theta_1}\\\\...\\\\\\frac{\\partial}{\\partial\\theta_n}\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Then\n",
    "\n",
    "\\begin{equation*}\n",
    "\\theta := \\theta - \\alpha\\nabla J(\\theta)\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "More generally:\n",
    "\n",
    "If you have a function f to map the space of m by n matrix A to a vector, \n",
    "\n",
    "Define:\n",
    "\n",
    "\\begin{equation*}\n",
    "\\nabla_A f(A) = \\begin{vmatrix}\n",
    "\\frac{\\partial f}{\\partial A_{11}}&\\frac{\\partial f}{\\partial A_{12}}&...&\\frac{\\partial f}{\\partial A_{1n}}\\\\\n",
    "\\frac{\\partial f}{\\partial A_{21}}&\\frac{\\partial f}{\\partial A_{22}}&...&\\frac{\\partial f}{\\partial A_{2n}}\\\\...&...&...&...\\\\\n",
    "\\frac{\\partial f}{\\partial A_{m1}}&\\frac{\\partial f}{\\partial A_{m2}}&...&\\frac{\\partial f}{\\partial A_{mn}}\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Also if m = n, define `trace`:\n",
    "\n",
    "\\begin{equation*}Tr(A) = \\sum_{i=1}^nA_{ii}\\end{equation*}\n",
    "\n",
    "Then the facts:\n",
    "\\begin{equation*}Tr(a) = a \\space \\space // \\space n=1\\end{equation*}\n",
    "\\begin{equation*}Tr(A) = Tr(A^T)\\end{equation*}\n",
    "\\begin{equation*}Tr(AB) = Tr(BA)\\end{equation*}\n",
    "\\begin{equation*}Tr(ABC) = Tr(CAB) = Tr(BCA)\\end{equation*}\n",
    "\n",
    "Also Suppose f(A) = Tr(AB), then:\n",
    "\n",
    "\\begin{equation*}\\nabla_A f(A) = \\nabla_A Tr(AB) = B^T\\end{equation*}\n",
    "\n",
    "And finally a tricky one:\n",
    "\\begin{equation*}\\nabla_A Tr(ABA^TC) = CBA + C^TAB^T\\end{equation*}\n",
    "\n",
    "By having all these facts above, define matrix X to be all the inputs from traninig set (the `design matrix`):\n",
    "\n",
    "\\begin{equation*}X = \\begin{vmatrix}x^{(1)T}\\\\x^{(2)T}\\\\..\\\\x^{(m)T}\\end{vmatrix}\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\n",
    "\\begin{equation*}X\\theta = \\begin{vmatrix}x^{(1)T}\\\\x^{(2)T}\\\\..\\\\^{(m)T}\\end{vmatrix}\\theta\n",
    "= \\begin{vmatrix}x^{(1)T}\\theta\\\\x^{(2)T}\\theta\\\\...\\\\x^{(m)T}\\theta\\end{vmatrix}\n",
    "= \\begin{vmatrix}h_\\theta(x^{(1)})\\\\h_\\theta(x^{(2)})\\\\...\\\\h_\\theta(x^{(m)})\\end{vmatrix}\n",
    "\\end{equation*}\n",
    "\n",
    "Define vector y as all the target values:\n",
    "\n",
    "\\begin{equation*}y = \\begin{vmatrix}y^{(1)}\\\\y^{(2)}\\\\..\\\\y^{(m)}\\end{vmatrix}\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*}X\\theta - y = \\begin{vmatrix}h_\\theta(x^{(1)})-y^{(1)}\\\\h_\\theta(x^{(2)})-y^{(2)}\\\\...\\\\h_\\theta(x^{(m)})-y^{(m)}\\end{vmatrix}\\end{equation*}\n",
    "\n",
    "Recall:\n",
    "\n",
    "\\begin{equation*} z^Tz = \\sum_iz_i^2\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*}\\frac12(X\\theta - y)^T(X\\theta - y) = \\frac12\\sum_{j=1}^m (h_\\theta(x^{(j)})-y^{(j)})^2 = J(\\theta)\\end{equation*}\n",
    "\n",
    "Try to solve **‚àá<sub>ùúÉ</sub>ùêΩ(ùúÉ) = 0** by using the facts above:\n",
    "\n",
    "\n",
    "\n",
    "\\begin{gather*}\\nabla_\\theta J(\\theta) \n",
    "= \\nabla_\\theta \\frac12(X\\theta - y)^T(X\\theta - y) \\\\\n",
    "= \\frac12 \\nabla_\\theta (X\\theta - y)^T(X\\theta - y) \\\\\n",
    "= \\frac12 \\nabla_\\theta (\\theta^TX^TX\\theta - \\theta^TX^Ty - y^TX\\theta + y^Ty) \\\\\n",
    "= \\frac12 \\nabla_\\theta Tr(\\theta^TX^TX\\theta - \\theta^TX^Ty - y^TX\\theta + y^Ty)  \\\\\n",
    "= \\frac12 ((\\nabla_\\theta Tr(\\theta\\theta^TX^TX) - \\nabla_\\theta Tr(y^TX\\theta) - \\nabla_\\theta Tr(y^TX\\theta) + 0)  \\\\\n",
    "= \\frac12 (X^TX\\theta + X^TX\\theta  - X^Ty - X^Ty) \\\\\n",
    "= X^TX\\theta - X^Ty) = 0 \n",
    "\\end{gather*}\n",
    "\n",
    "So \n",
    "\n",
    "\\begin{equation*} X^TX\\theta = X^Ty\\end{equation*}\n",
    "\n",
    "The equation is called the `normal equations` and we can slove:\n",
    "\n",
    "\\begin{equation*} \\theta = (X^TX)^{-1}X^Ty\\end{equation*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lecture 3\n",
    "\n",
    "- Linear Regression \n",
    " - Locally Weighted Regression\n",
    "- Portabilistic Interperception\n",
    "- Logistic Regression\n",
    "  - Digression Perception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The problem\n",
    "\n",
    "If the features are poorly chosen, the model can be\n",
    " - underfitting\n",
    " - overfitting\n",
    " \n",
    "For now we use a class of algorisms called `non-parametric learning algorism` that help to alleviate this problem.\n",
    "\n",
    "- parametric:  fixed ùúÉs\n",
    "- non-parametric: no. of parameters grows with m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Locally Weighted Regression\n",
    "\n",
    " - also called `loess` or `lowess`\n",
    " - non-parametric learning algorism\n",
    " \n",
    "LWR: fit ùúÉ to minimise \n",
    " \n",
    "\\begin{align} \\sum_iw^{(i)}(y^{(i)}-\\theta^TX^{(i)})^2 \\end{align}\n",
    " \n",
    "Where\n",
    " \n",
    "\\begin{equation*} w^{(i)} = \\exp(-\\frac{(x^{(i)} - x)^2}{2 \\tau}) \\end{equation*}\n",
    "  \n",
    " - If |x<sup>(i)</sup> - x| is small, then w<sup>(i)</sup> is close to 1.\n",
    " - If |x<sup>(i)</sup> - x| is large, then w<sup>(i)</sup> is close to 0.\n",
    " - ùúè (bandwith) controls how rapidly the weight drops\n",
    " \n",
    "When doing predictions, it needs to fit ùúÉ to the entire tranning set again.\n",
    "\n",
    "And it doesn't solve the problem if ùúè is badly chosen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Portabilistic Interperception\n",
    "\n",
    "Assume\n",
    "\n",
    "\\begin{equation*} y^{(i)} = \\theta^Tx^{(i)} + \\epsilon^{(i)} \\end{equation*}\n",
    "\n",
    "\\begin{equation*} \\epsilon^{(i)} = error \\end{equation*}\n",
    "\n",
    "Assume ùúñ<sup>(i)</sup> have a portability distribution - called `Normal Distribution` or `Gaussion Distribution`:\n",
    "\\begin{align} N(0, \\sigma^2) \\end{align}\n",
    "\n",
    "**Why?**\n",
    " - it's mathematically convinient\n",
    " = for most of the problems it works...\n",
    "\n",
    "So the portability distribution of ùúñ<sup>(i)</sup>:\n",
    "\n",
    "\\begin{equation*} P(\\epsilon^{(i)}) = \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{{\\epsilon^{(i)}}^2}{2\\sigma^2}) \\end{equation*}\n",
    "\n",
    "This implies that the portability distribution of y<sup>(i)</sup> by given x<sup>(i)</sup> and ùúÉ:\n",
    "\n",
    "\\begin{equation*} P(y^{(i)}|x^{(i)}, \\theta) = \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\theta^Tx^{(i)}})^2}{2\\sigma^2}) \\end{equation*}\n",
    "\n",
    "Also writen as: \\begin{align} N(\\theta^Tx^{(i)}, \\sigma^2) \\end{align}\n",
    "\n",
    "One more assumption is that ùúñ<sup>(i)</sup> is IID, which mean they are independently identically distributed.\n",
    "\n",
    "Then define the likelihood of ùúÉ:\n",
    "\n",
    "\\begin{equation*} L(\\theta) = \\prod_1^m P(y|X, \\theta) = \\prod_1^m \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\theta^Tx^{(i)}})^2}{2\\sigma^2}) \\end{equation*}\n",
    "\n",
    "`Likelihood` here is actually portability.\n",
    "\n",
    "Then we need to maximise the `Likelihood`: choose ùúÉ to maximise the ùêø(ùúÉ).\n",
    "\n",
    "Define \\begin{gather*} l(\\theta) = \\log L(\\theta) = \\log \\prod_1^m \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\theta^Tx^{(i)}})^2}{2\\sigma^2}) \\\\ \n",
    "= \\sum_1^m \\log  \\frac1{\\sqrt{2\\pi}\\sigma}\\exp (-\\frac{({y^{(i)}-\\theta^Tx^{(i)}})^2}{2\\sigma^2}) \\\\\n",
    "= m \\log \\frac1{\\sqrt{2\\pi}\\sigma} + \\sum_1^m(-\\frac{({y^{(i)}-\\theta^Tx^{(i)}})^2}{2\\sigma^2})\n",
    "\\end{gather*}\n",
    "\n",
    "So maximising ùëô(ùúÉ) is the same as minimising \n",
    "\\begin{equation*} \\frac12 \\sum_1^m ({y^{(i)}-\\theta^Tx^{(i)}})^2 = J(\\theta) \\end{equation*}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "\n",
    "Generally it's a bad idea to apply linear regression to classification problems.\n",
    "\n",
    "When we need to classify \\begin{align}y \\space \\epsilon \\space \\{0, 1\\}  \\end{align} with a prediction function: \n",
    "\n",
    "\\begin{align}h_\\theta (x) \\space \\epsilon \\space [0, 1]  \\end{align}\n",
    "\n",
    "Then choose:\n",
    "\n",
    "\\begin{align}h_\\theta (x) = g(\\theta^Tx) = \\frac1{1+e^{-\\theta^Tx}}\\end{align}\n",
    "\n",
    "\n",
    "The function `g` here:\n",
    "\n",
    "\\begin{align} g(z) = \\frac1{1+e^{-z}}\\end{align}\n",
    "\n",
    "is called `sigmond function` or `logistic function`.\n",
    "\n",
    "There are reasons of chosing this function.\n",
    "\n",
    "Then it comes to the portability of y=1 or y=0:\n",
    "\n",
    "\\begin{equation*} P(y=1|x;\\theta) = h_\\theta(x) \\end{equation*}\n",
    "\\begin{equation*} P(y=0|x;\\theta) = 1 - h_\\theta(x) \\end{equation*}\n",
    "\n",
    "Write them in one line:\n",
    "\n",
    "\\begin{equation*} P(y|x;\\theta) = h_\\theta(x)^y(1-h_\\theta(x)^{1-y}) \\end{equation*}\n",
    "\n",
    "Then the likely hood of ùúÉ:\n",
    "\n",
    "\\begin{equation*} L(\\theta) = \\prod_{i}ùëÉ(ùë¶^{(i)}|ùëã^{(i)},ùúÉ) = \\prod_i h_\\theta(x^{(i)})^{y^{(i)}}(1-h_\\theta(x^{(i)})^{1-y^{(i)}})\\end{equation*}\n",
    "\n",
    "Then:\n",
    "\n",
    "\\begin{equation*} l(\\theta) = \\log L(\\theta) = \\log \\prod_i h_\\theta(x^{(i)})^{y^{(i)}}(1-h_\\theta(x^{(i)})^{1-y^{(i)}})\n",
    "= \\sum_1^my^{(i)}\\log h_\\theta(x^{(i)}) + (1-y^{(i)})\\log(1-h_\\theta(x^{(i)}))\n",
    "\\end{equation*}\n",
    "\n",
    "The algorism to mixmise this l(ùúÉ) is similar to Gradient Descent => Gradient Ascent:\n",
    "\n",
    "\\begin{equation*}\\theta := \\theta + \\alpha \\nabla_\\theta l(\\theta) \\end{equation*}\n",
    "\n",
    "Since:\n",
    "\n",
    "\\begin{equation*}\\frac{\\partial}{\\partial \\theta_j}l(\\theta) = \\sum_{i=1}^m (y^{(i)}-h_\\theta(x^{(i)}))x_j^{(i)} \\end{equation*}\n",
    "\n",
    "It turns out that Gradient Ascent:\n",
    "\n",
    "\\begin{equation*}\\theta_j := \\theta_j + \\alpha \\sum_{i=1}^m (y^{(i)}-h_\\theta(x^{(i)}))x_j^{(i)} \\end{equation*}\n",
    "\n",
    "This looks the same as formular in Batch Gradient Descent expect that there is a + not -. However, this is a totally a different algorism and the key difference is the function **h<sub>ùúÉ</sub>(x<sup>(i)</sup>)**, which is not a linear function any more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Digression Perception\n",
    "\n",
    "Change the sigmond funtion to another function (step function):\n",
    "\n",
    "g(z) when z>=0 then 1 else 0.\n",
    "\n",
    "This become a simpler algorism than logistic regression and later on we can use this as a building block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
